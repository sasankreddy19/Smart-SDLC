{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24192d64561e4abf921cfa1ba351a4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2d6077748c04c019002429dfab2ab4e",
              "IPY_MODEL_5d04d00e64ee412bbb523bbd6274ae88",
              "IPY_MODEL_66780c69250a44daaeb5c9c13bc1be92"
            ],
            "layout": "IPY_MODEL_1289f44e5adb4745a3f7f8e126b64a99"
          }
        },
        "a2d6077748c04c019002429dfab2ab4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a07068df174f40bb8a87e7937182f882",
            "placeholder": "​",
            "style": "IPY_MODEL_d7d4aaa3467f4cc2b60fc4f5505ae043",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5d04d00e64ee412bbb523bbd6274ae88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6710c19bb0f044c0aa1681452384d960",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bd27a8b587848ac9f244a92f9c334d1",
            "value": 2
          }
        },
        "66780c69250a44daaeb5c9c13bc1be92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4ff0f1afe9d4a15a7cb7133a3ab1952",
            "placeholder": "​",
            "style": "IPY_MODEL_dcfa9b30aa794f7084db0af635fafd94",
            "value": " 2/2 [00:12&lt;00:00, 12.59s/it]"
          }
        },
        "1289f44e5adb4745a3f7f8e126b64a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07068df174f40bb8a87e7937182f882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d4aaa3467f4cc2b60fc4f5505ae043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6710c19bb0f044c0aa1681452384d960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd27a8b587848ac9f244a92f9c334d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4ff0f1afe9d4a15a7cb7133a3ab1952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcfa9b30aa794f7084db0af635fafd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio transformers torch accelerate bitsandbytes pyngrok -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HbXJeSngL5D",
        "outputId": "f91fcc1d-df1f-4204-df40-f630cef31d0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timeout-decorator -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGKAeX-kgL6_",
        "outputId": "22cfc2fe-3a06-4a9c-ed10-78bd81458e1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_yBMlzKgL8y",
        "outputId": "15db919c-90a1-4cb7-bc79-2dbde049b600"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=c2a227107fb8323c971c20b37fa27aeb762b705ed861cb84f6823932c9f01c77\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install black radon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-5S74tqgL-t",
        "outputId": "0a7457fc-11be-49e0-aedd-94ab1ee8a97e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting black\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting radon\n",
            "  Downloading radon-6.0.1-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black) (8.2.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.11/dist-packages (from black) (24.2)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black) (4.3.8)\n",
            "Collecting mando<0.8,>=0.6 (from radon)\n",
            "  Downloading mando-0.7.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorama>=0.4.1 (from radon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mando<0.8,>=0.6->radon) (1.17.0)\n",
            "Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading radon-6.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading mando-0.7.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pathspec, mypy-extensions, mando, colorama, radon, black\n",
            "Successfully installed black-25.1.0 colorama-0.4.6 mando-0.7.1 mypy-extensions-1.1.0 pathspec-0.12.1 radon-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycodestyle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL-JmUeugMA9",
        "outputId": "9c20758d-7f9a-42e8-d959-2189cebb7263"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycodestyle\n",
            "  Downloading pycodestyle-2.13.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Downloading pycodestyle-2.13.0-py2.py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pycodestyle\n",
            "Successfully installed pycodestyle-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNHuJD35gMCr",
        "outputId": "765d96b2-c585-4de2-95ca-739ca0e766f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bandit safety\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NTZPLlyLgMEx",
        "outputId": "e75f764b-a5a7-46b8-8248-6d157a4f904f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bandit\n",
            "  Downloading bandit-1.8.5-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting safety\n",
            "  Downloading safety-3.5.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from bandit) (6.0.2)\n",
            "Collecting stevedore>=1.20.0 (from bandit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from bandit) (13.9.4)\n",
            "Collecting authlib>=1.2.0 (from safety)\n",
            "  Downloading authlib-1.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting click<8.2.0,>=8.0.2 (from safety)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting dparse>=0.6.4 (from safety)\n",
            "  Downloading dparse-0.6.4-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting filelock~=3.16.1 (from safety)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from safety) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from safety) (3.1.6)\n",
            "Collecting marshmallow>=3.15.0 (from safety)\n",
            "  Downloading marshmallow-4.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from safety) (3.9.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.11/dist-packages (from safety) (24.2)\n",
            "Collecting psutil~=6.1.0 (from safety)\n",
            "  Downloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pydantic<2.10.0,>=2.6.0 (from safety)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from safety) (2.32.3)\n",
            "Collecting ruamel-yaml>=0.17.21 (from safety)\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting safety-schemas==0.0.14 (from safety)\n",
            "  Downloading safety_schemas-0.0.14-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from safety) (75.2.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from safety) (9.1.2)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from safety) (0.13.3)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from safety) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from safety) (4.14.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib>=1.2.0->safety) (43.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.0->safety) (3.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->safety) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->safety) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->safety) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.10.0,>=2.6.0->safety) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<2.10.0,>=2.6.0->safety)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml>=0.17.21->safety)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=1.20.0->bandit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->safety) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->bandit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->bandit) (2.19.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->safety) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->safety) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->safety) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->safety) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->safety) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->safety) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->safety) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->bandit) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->safety) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib>=1.2.0->safety) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib>=1.2.0->safety) (2.22)\n",
            "Downloading bandit-1.8.5-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safety-3.5.2-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.0/274.0 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safety_schemas-0.0.14-py3-none-any.whl (39 kB)\n",
            "Downloading authlib-1.6.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dparse-0.6.4-py3-none-any.whl (11 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading marshmallow-4.0.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, pydantic-core, psutil, pbr, marshmallow, filelock, dparse, click, stevedore, ruamel-yaml, pydantic, safety-schemas, bandit, authlib, safety\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.5\n",
            "    Uninstalling pydantic-2.11.5:\n",
            "      Successfully uninstalled pydantic-2.11.5\n",
            "Successfully installed authlib-1.6.0 bandit-1.8.5 click-8.1.8 dparse-0.6.4 filelock-3.16.1 marshmallow-4.0.0 pbr-6.1.1 psutil-6.1.1 pydantic-2.9.2 pydantic-core-2.23.4 ruamel-yaml-0.18.14 ruamel.yaml.clib-0.2.12 safety-3.5.2 safety-schemas-0.0.14 stevedore-5.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "5df330a31060456394d873d8582e25d6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHZHY7D2gZdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "import ast\n",
        "import random\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import logging\n",
        "import time\n",
        "import timeout_decorator\n",
        "import requests\n",
        "import hashlib\n",
        "import black\n",
        "from radon.complexity import cc_visit\n",
        "import pycodestyle\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "\n",
        "\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    \"output_dir\": \"/content/output\",\n",
        "    \"max_file_size\": 1048576,\n",
        "    \"model_path\": \"ibm-granite/granite-3.3-2b-instruct\",\n",
        "    \"use_quantization\": False\n",
        "}\n",
        "\n",
        "cache = {}\n",
        "\n",
        "@timeout_decorator.timeout(300)\n",
        "def load_granite_model():\n",
        "    logger.info(f\"Loading model: {config['model_path']}...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config[\"model_path\"])\n",
        "        kwargs = {\n",
        "            \"device_map\": \"auto\",\n",
        "            \"torch_dtype\": torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "        }\n",
        "        if config[\"use_quantization\"]:\n",
        "            kwargs[\"quantization_config\"] = BitsAndBytesConfig(load_in_4bit=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(config[\"model_path\"], **kwargs)\n",
        "        model.eval()\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Model load failed: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "try:\n",
        "    model, tokenizer = load_granite_model()\n",
        "except timeout_decorator.TimeoutError:\n",
        "    model, tokenizer = None, None\n",
        "\n",
        "def handle_file(file):\n",
        "    if file is None:\n",
        "        return None, \"No file uploaded.\"\n",
        "    try:\n",
        "        file_path = file.name if hasattr(file, 'name') else str(file)\n",
        "        temp_file_path = f\"/content/{os.path.basename(file_path)}_{int(time.time())}.py\"\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            file_content = f.read()\n",
        "        with open(temp_file_path, \"wb\") as f:\n",
        "            f.write(file_content)\n",
        "        return temp_file_path, None\n",
        "    except Exception as e:\n",
        "        return None, f\"Error processing file: {str(e)}\"\n",
        "\n",
        "def read_file(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def fetch_github_file(github_url):\n",
        "    try:\n",
        "        parts = github_url.split('/')\n",
        "        if len(parts) < 7 or 'github.com' not in parts:\n",
        "            return None, \"Invalid GitHub URL\"\n",
        "        owner, repo, _, _, *path = parts[3:]\n",
        "        path = '/'.join(path)\n",
        "        api_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"\n",
        "        headers = {\"Accept\": \"application/vnd.github.v3.raw\"}\n",
        "        response = requests.get(api_url, headers=headers)\n",
        "        if response.status_code != 200:\n",
        "            return None, f\"Failed to fetch file: {response.status_code}\"\n",
        "        temp_file_path = f\"/content/github_file_{int(time.time())}.py\"\n",
        "        with open(temp_file_path, \"w\", encoding='utf-8') as f:\n",
        "            f.write(response.text)\n",
        "        return temp_file_path, None\n",
        "    except Exception as e:\n",
        "        return None, f\"Error fetching GitHub file: {str(e)}\"\n",
        "\n",
        "def granite_generate(prompt, model_instance, tokenizer_instance, max_tokens=2000):\n",
        "    if model_instance is None or tokenizer_instance is None:\n",
        "        return \"Error: Model not loaded.\"\n",
        "    try:\n",
        "        key = hashlib.sha256(prompt.encode()).hexdigest()\n",
        "        if key in cache:\n",
        "            return \"[🔁 From Cache]\\n\\n\" + cache[key]\n",
        "\n",
        "        start = time.time()\n",
        "        inputs = tokenizer_instance(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        output = model_instance.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_tokens,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer_instance.eos_token_id\n",
        "        )\n",
        "        decoded_output = tokenizer_instance.decode(output[0], skip_special_tokens=True)\n",
        "        result = decoded_output[len(prompt):].strip() if decoded_output.startswith(prompt) else decoded_output.strip()\n",
        "        result = f\"[⏱️ Took {round(time.time() - start, 2)}s]\\n\\n{result}\"\n",
        "        cache[key] = result\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return \"Error during generation.\"\n",
        "\n",
        "def process_code_with_llm(file, github_url, prompt_template):\n",
        "    path, err = (handle_file(file) if file else fetch_github_file(github_url)) if (file or github_url) else (None, \"No input provided.\")\n",
        "    if err:\n",
        "        return err\n",
        "    content = read_file(path)\n",
        "    if content is None:\n",
        "        return \"Error: Could not read file content.\"\n",
        "    if model is None or tokenizer is None:\n",
        "        return \"Error: Model not loaded.\"\n",
        "    prompt = prompt_template.format(content=content)\n",
        "    return granite_generate(prompt, model, tokenizer)\n",
        "\n",
        "def process_text_with_llm(text, prompt_template):\n",
        "    return granite_generate(prompt_template.format(content=text), model, tokenizer) if text else \"❌ No input text provided.\"\n",
        "\n",
        "def generate_docstrings_gradio(file, github_url):\n",
        "    return process_code_with_llm(\n",
        "        file,\n",
        "        github_url,\n",
        "        \"Add or update Google-style Python docstrings for all functions and classes in the following code:\\n\\n{content}\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def review_code_gradio(file, github_url):\n",
        "    return process_code_with_llm(\n",
        "        file,\n",
        "        github_url,\n",
        "        (\n",
        "            \"You are an expert software engineer and code reviewer. Analyze the following source code in depth. \"\n",
        "            \"Perform a professional code review covering the following:\\n\\n\"\n",
        "            \"- ✅ Code correctness and logical flaws\\n\"\n",
        "            \"- 📐 Time and space complexity analysis of functions\\n\"\n",
        "            \"- 🔒 Security vulnerabilities or unsafe operations\\n\"\n",
        "            \"- 🧠 Readability and maintainability (naming, structure, comments)\\n\"\n",
        "            \"- ♻️ Reusability and modularity\\n\"\n",
        "            \"- ⚡ Performance and optimization suggestions\\n\"\n",
        "            \"- 🧰 Use of language-specific best practices\\n\"\n",
        "            \"- 📊 Highlight code smells, dead code, or anti-patterns\\n\\n\"\n",
        "            \"Provide constructive feedback and suggestions. Use bullet points or sections for clarity.\\n\\n\"\n",
        "            \"{content}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def predict_bugs_gradio(file, github_url):\n",
        "    return process_code_with_llm(\n",
        "        file,\n",
        "        github_url,\n",
        "        \"Analyze the following Python code and Identify potential bugs, logic errors, or unsafe code patterns in the following Python code.Provide explanations and suggestions Which  Explain each issue clearly:\\n\\n{content}\"\n",
        "    )\n",
        "\n",
        "def generate_report_gradio(file, github_url, template=\"Summary\"):\n",
        "    templates = {\n",
        "        \"Summary\": (\n",
        "        \"You are a software analyst. Read the following source code and generate a high-level summary. \"\n",
        "        \"Include the purpose of the project, the main components, and key functionalities:\\n\\n{content}\"\n",
        "    ),\n",
        "    \"Detailed\": (\n",
        "        \"You are a senior software architect. Analyze the following source code and generate a detailed technical report. \"\n",
        "        \"Include architecture overview, class/function responsibilities, key algorithms, third-party libraries used, and code organization:\\n\\n{content}\"\n",
        "    ),\n",
        "    \"Executive Summary\": (\n",
        "        \"You are preparing a technical executive summary for non-developers. Summarize the following codebase by explaining its purpose, \"\n",
        "        \"high-level functionality, use cases, and business value in simple terms without deep technical jargon:\\n\\n{content}\"\n",
        "    )\n",
        "    }\n",
        "    return process_code_with_llm(file, github_url, templates.get(template, templates[\"Summary\"]))\n",
        "\n",
        "def summarize_requirements_gradio(txt):\n",
        "    return process_text_with_llm(\n",
        "        txt,\n",
        "        \"Summarize the following software requirements clearly and concisely:\\n\\n{content}\"\n",
        "    )\n",
        "\n",
        "def generate_code_gradio(txt):\n",
        "    return process_text_with_llm(\n",
        "        txt,\n",
        "        \"Generate well-structured Python code based on the following software requirements:\\n\\n{content}\"\n",
        "    )\n",
        "\n",
        "def code_metrics(file, github_url):\n",
        "    return process_code_with_llm(\n",
        "        file,\n",
        "        github_url,\n",
        "        \"Using static analysis, provide code metrics for the following code. Include total lines of code, number of functions, number of classes, average function length, and any other useful structural insights:\\n\\n{content}\"\n",
        "    )\n",
        "\n",
        "def optimization_suggestions(file, github_url):\n",
        "    return process_code_with_llm(\n",
        "        file,\n",
        "        github_url,\n",
        "        (\n",
        "        \"Analyze the following Python code and suggest optimizations for performance, readability, and maintainability. Include clear explanations with best Pratices:\\n\\n\"\n",
        "        \"Format the output using Markdown with emoji headers, bullet points, and code blocks if necessary.\\n\"\n",
        "        \"{content}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_security_report(file, github_url):\n",
        "    report = process_code_with_llm(\n",
        "        file,\n",
        "        github_url,\n",
        "        (\n",
        "            \"You are a cybersecurity expert. Review the following code and generate a **detailed security report** in Markdown format.\\n\\n\"\n",
        "            \"Your output should include:\\n\"\n",
        "            \"- 🧠 **Overview of the code's purpose**\\n\"\n",
        "            \"- 🔍 **Detected Vulnerabilities** (with severity: 🔴/🟡/🟢)\\n\"\n",
        "            \"- 💡 **Root Causes** of each issue\\n\"\n",
        "            \"- 🛠️ **Fix Recommendations**\\n\"\n",
        "            \"- ✅ *If no issues are found, state that the code is secure and explain why.*\\n\\n\"\n",
        "            \"Format your output using Markdown:\\n\"\n",
        "            \"# 🛡️ Security Report\\n\"\n",
        "            \"## 🔍 Findings\\n\"\n",
        "            \"**Example:** 🔴 Hardcoded password found in `config.py` line 12.\\n\\n\"\n",
        "            \"{content}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if not report or not report.strip():\n",
        "        return \"❌ Failed to generate report.\"\n",
        "\n",
        "    return report\n",
        "\n",
        "\n",
        "def generate_tests_from_requirements(txt):\n",
        "    return process_text_with_llm(\n",
        "        txt,\n",
        "        (\n",
        "            \"You are an assistant generating function test inputs.\\n\"\n",
        "            \"Based on the following software description or function, generate only a set of meaningful test input values.\\n\\n\"\n",
        "            \"- Include normal cases, edge cases, and invalid inputs\\n\"\n",
        "            \"- Only output the input values (e.g., tuples or function arguments)\\n\"\n",
        "            \"- No explanations, no output validation\\n\"\n",
        "            \"- Use Python-like syntax for clarity\\n\\n\"\n",
        "            \"Function or Requirement:\\n{content}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "def apply_fix_to_output(text):\n",
        "    return process_text_with_llm(\n",
        "        text,\n",
        "        \"You are a senior software developer. Analyze the following code. If it contains bugs or flaws, return a corrected version. \"\n",
        "        \"If it is correct and clean, respond with: '✅ No issues detected. Code is clean and correct.'\\n\\n{content}\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def live_threat_alerts():\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    threat_types = {\n",
        "        \"ALERT\": [\n",
        "            \"Unauthorized access attempt detected.\",\n",
        "            \"Execution of suspicious binary logged.\",\n",
        "            \"Rapid login failures from single IP.\",\n",
        "            \"Possible reverse shell detected.\"\n",
        "        ],\n",
        "        \"INFO\": [\n",
        "            \"System integrity check passed.\",\n",
        "            \"No critical CVEs detected.\",\n",
        "            \"Firewall rules validated.\",\n",
        "            \"Security definitions updated.\"\n",
        "        ],\n",
        "        \"WARNING\": [\n",
        "            \"Unusual outbound traffic on port 22.\",\n",
        "            \"Deprecated function used in sensitive area.\",\n",
        "            \"High script execution time.\",\n",
        "            \"Access from unrecognized country.\"\n",
        "        ],\n",
        "        \"ACTION\": [\n",
        "            \"Blocked IP temporarily.\",\n",
        "            \"Triggered file integrity scan.\",\n",
        "            \"Restarted vulnerable service.\",\n",
        "            \"Generated alert for SOC review.\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    def log(level, msg): return f\"[{now}] [{level}] {msg}\"\n",
        "\n",
        "    logs = []\n",
        "    for category, messages in threat_types.items():\n",
        "        logs.append(log(category, random.choice(messages)))\n",
        "\n",
        "    return \"\\n\".join(random.sample(logs, 3))\n",
        "\n",
        "    def generate_log(level, message):\n",
        "        return f\"[{now}] [{level}] {message}\"\n",
        "\n",
        "    logs = []\n",
        "    for category, messages in threat_types.items():\n",
        "        message = random.choice(messages)\n",
        "        logs.append(generate_log(category, message))\n",
        "\n",
        "    return \"\\n\".join(random.sample(logs, k=3))\n",
        "\n",
        "with gr.Blocks(theme=\"earneleh/paris\") as demo:\n",
        "    gr.Markdown(\"# 🧠 SmartSDLC: AI-Enhanced Software Development Lifecycle\")\n",
        "\n",
        "    with gr.Tab(\"Code Analysis\"):\n",
        "        file_input = gr.File(label=\"📄 Upload Code File\", file_types=[\".py\"])\n",
        "        github_input = gr.Textbox(label=\"🔗 GitHub File URL\")\n",
        "        task_dropdown = gr.Dropdown(\n",
        "            label=\"Select a Task\",\n",
        "            choices=[\n",
        "                \"None\", \"📝 Generate Docstrings\", \"🧪 Review Code\", \"🐞 Predict Bugs\",\n",
        "                \"📊 Generate Project Report\", \"📏 Code Metrics\", \"⚙️ Optimization Suggestions\"\n",
        "            ],\n",
        "            value=\"None\"\n",
        "        )\n",
        "        report_template = gr.Dropdown(visible=False, choices=[\"Summary\", \"Detailed\", \"Executive Summary\"], label=\"📄 Report Template\")\n",
        "        output_box = gr.Code(label=\"🔍 Output\", language=\"python\")\n",
        "\n",
        "        # 📄 Report Template Dropdown\n",
        "        report_template_dropdown = gr.Dropdown(\n",
        "            label=\"📄 Report Template\",\n",
        "            choices=[\"Summary\", \"Detailed\", \"Executive Summary\"],\n",
        "            value=\"Summary\",\n",
        "            visible=False\n",
        "        )\n",
        "        code_output = gr.Code(label=\"🔍 Output\", language=\"python\")\n",
        "\n",
        "        # 👁️ Show/hide the report template selector based on task\n",
        "        def toggle_template_visibility(choice):\n",
        "            return gr.update(visible=(choice == \"📊 Generate Project Report\"))\n",
        "\n",
        "        # 🧠 Run selected task\n",
        "        def handle_code_task(choice, file, github, template):\n",
        "            task_map = {\n",
        "                \"📝 Generate Docstrings\": generate_docstrings_gradio,\n",
        "                \"🧪 Review Code\": review_code_gradio,\n",
        "                \"🐞 Predict Bugs\": predict_bugs_gradio,\n",
        "                \"📊 Generate Project Report\": lambda f, g: generate_report_gradio(f, g, template),\n",
        "                \"📏 Code Metrics\": code_metrics,\n",
        "                \"⚙️ Optimization Suggestions\": optimization_suggestions\n",
        "            }\n",
        "\n",
        "            if choice == \"None\":\n",
        "                return \"⚠️ Please select a valid task.\"\n",
        "\n",
        "            return task_map[choice](file, github) if choice in task_map else \"❌ Invalid task.\"\n",
        "\n",
        "        # 🔁 Change handlers\n",
        "        task_dropdown.change(\n",
        "            fn=toggle_template_visibility,\n",
        "            inputs=task_dropdown,\n",
        "            outputs=report_template_dropdown\n",
        "        )\n",
        "\n",
        "        task_dropdown.change(\n",
        "            fn=handle_code_task,\n",
        "            inputs=[task_dropdown, file_input, github_input, report_template_dropdown],\n",
        "            outputs=code_output\n",
        "        )\n",
        "\n",
        "        report_template_dropdown.change(\n",
        "            fn=handle_code_task,\n",
        "            inputs=[task_dropdown, file_input, github_input, report_template_dropdown],\n",
        "            outputs=code_output\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Tab(\"Functional Analysis\"):\n",
        "        req_input = gr.Textbox(label=\"📘 Enter Requirements\", lines=8)\n",
        "        with gr.Row():\n",
        "            req_summarize = gr.Button(\"🔎 Summarize\")\n",
        "            req_generate = gr.Button(\"💻 Generate Code\")\n",
        "            req_testgen = gr.Button(\"🧪 Generate Test Cases\")\n",
        "        req_output = gr.Code(label=\"📋 Output\", language=\"python\")\n",
        "\n",
        "        req_summarize.click(fn=summarize_requirements_gradio, inputs=req_input, outputs=req_output)\n",
        "        req_generate.click(fn=generate_code_gradio, inputs=req_input, outputs=req_output)\n",
        "        req_testgen.click(fn=generate_tests_from_requirements, inputs=req_input, outputs=req_output)\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Tab(\"Security Monitor\"):\n",
        "        with gr.Column():\n",
        "            # 🔍 File upload for security scan\n",
        "            security_file_input = gr.File(\n",
        "                label=\"📁 Upload File for Security Scan\",\n",
        "                file_types=[\".py\"]\n",
        "            )\n",
        "\n",
        "            # 👀 Simulate live threat alerts\n",
        "            threat_button = gr.Button(\"👀 Simulate Live Alerts\")\n",
        "            threat_output = gr.Textbox(label=\"⚠️ Threat Monitor\", lines=10)\n",
        "            threat_button.click(fn=lambda: live_threat_alerts(), outputs=threat_output)\n",
        "\n",
        "            # 🛡️ LLM-based security report generation\n",
        "            gr.Markdown(\"## 🛡️ Generate Detailed Security Report\")\n",
        "            security_github_input = gr.Textbox(label=\"🔗 Optional GitHub File URL\")\n",
        "            generate_sec_btn = gr.Button(\"📄 Generate Security Report\")\n",
        "            security_report_output = gr.Code(label=\"🔍 Security Report\", language=\"markdown\", interactive=True)\n",
        "\n",
        "            generate_sec_btn.click(\n",
        "            fn=generate_security_report,\n",
        "            inputs=[security_file_input, security_github_input],\n",
        "            outputs=security_report_output  # return both\n",
        "            )\n",
        "\n",
        "    fix_button = gr.Button(\"🛠️ Apply Fix\")\n",
        "    fix_button.click(fn=apply_fix_to_output, inputs=code_output, outputs=code_output)\n",
        "\n",
        "\n",
        "\n",
        "    feedback_slider = gr.Slider(1, 5, label=\"Rate the Output\")\n",
        "    feedback_btn = gr.Button(\"👍 Submit Feedback\")\n",
        "    feedback_btn.click(lambda r, o: \"✅ Thanks for your feedback!\" if o else \"⚠️ No output to rate.\", inputs=[feedback_slider, output_box], outputs=output_box)\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678,
          "referenced_widgets": [
            "24192d64561e4abf921cfa1ba351a4d2",
            "a2d6077748c04c019002429dfab2ab4e",
            "5d04d00e64ee412bbb523bbd6274ae88",
            "66780c69250a44daaeb5c9c13bc1be92",
            "1289f44e5adb4745a3f7f8e126b64a99",
            "a07068df174f40bb8a87e7937182f882",
            "d7d4aaa3467f4cc2b60fc4f5505ae043",
            "6710c19bb0f044c0aa1681452384d960",
            "3bd27a8b587848ac9f244a92f9c334d1",
            "b4ff0f1afe9d4a15a7cb7133a3ab1952",
            "dcfa9b30aa794f7084db0af635fafd94"
          ]
        },
        "id": "fgXVMQB1gZgJ",
        "outputId": "0d69d8bd-d93d-4df2-bad6-de3a28c407e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24192d64561e4abf921cfa1ba351a4d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7b640ac7b00073861e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7b640ac7b00073861e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://7b640ac7b00073861e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K65YnNXWgZiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kntmRGVKgZkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hfD4hqYNgZmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Slc0TXgvgZqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5j0RPvLFgMGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bkNy1yQgMJ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}